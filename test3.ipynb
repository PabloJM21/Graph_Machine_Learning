{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb719674-c334-440d-af62-1aed8c57f1ec",
   "metadata": {},
   "source": [
    "# Dense GNN implementation\n",
    "\n",
    "In this exercise we are implementing a GNN from scratch using dense matrices.\n",
    "Note that as the memory requirement of a dense matrix scales quadratically with the number of nodes in a graph, this limits us to datasets with only small graphs. \n",
    "\n",
    "We will use the following dataset molHIV.\n",
    "\n",
    "For the network we need a message-passing layer and pooling function.\n",
    "\n",
    "1. Describe the datasets in your own words. Also talk about its features and statistical properties of the graphs and labels.\n",
    "1. Implement the class GCNLayer to perform one round of message passing. You may use any variant of message passing here.\n",
    "1. Implement a pooling layer like MeanPooling or SumPooling (or both).\n",
    "1. Implement a one-hot-encoding of the atom type (this will positively affect classification performance)\n",
    "1. Implement the model class GraphGCN that builds upon your GCNLayer and Pooling layer.\n",
    "1. Create and train a GraphGCN model on MolHIV. As MOlHIV is highly imbalanced, it will make sense to adapt class weights in your loss function.\n",
    "\n",
    "For the dataset molHIV we aim to reach something like 0.64 ROC (or higher). Note that for me the training was quite unstable, so several runs got stuck at 0.5.\n",
    "\n",
    "Note: In this exercise, we use PyG only for utilities and not to build models. Feel free to edit/ignore any of the provided code as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "id": "78608f62-c77d-4f16-a924-50843e5bcc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:48.566117Z",
     "start_time": "2024-10-28T12:45:48.558493Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import numpy as np\n",
    "from ogb.graphproppred import PygGraphPropPredDataset,Evaluator\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "906e13d0-cf25-450f-948c-c8f3fa214850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:48.798321Z",
     "start_time": "2024-10-28T12:45:48.788043Z"
    }
   },
   "source": [
    "# find device\n",
    "if torch.cuda.is_available(): # NVIDIA\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # apple silicon\n",
    "    device = torch.device('mps') \n",
    "else:\n",
    "    device = torch.device('cpu') # fallback\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "76a3a3e8-b9cb-42d7-be0f-8c41a1304a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:48.880896Z",
     "start_time": "2024-10-28T12:45:48.872310Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=torch.nn.functional.relu):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, H: torch.Tensor, adj: torch.Tensor):\n",
    "        # Precompute normalized adjacency matrix for stability\n",
    "        D_inv_sqrt = torch.diag(torch.pow(adj.sum(dim=-1), -0.5))  # Degree matrix\n",
    "        adj_norm = D_inv_sqrt @ adj @ D_inv_sqrt  # Normalize adjacency matrix\n",
    "\n",
    "        # Message passing\n",
    "        H = adj_norm @ H @ self.weight  # Propagate information\n",
    "        H = self.activation(H)  # Apply nonlinearity\n",
    "        return H\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "f07521e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:48.941843Z",
     "start_time": "2024-10-28T12:45:48.933614Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "class MeanPooling(torch.nn.Module):\n",
    "    def __init__(self, dim: int | tuple[int, ...] = 1):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, H: torch.Tensor):\n",
    "        # Compute mean across the specified dimension(s)\n",
    "        return H.mean(dim=self.dim)\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "0bc412b3-5648-4f1f-88a0-f5a18a27a419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:45:48.960524Z",
     "start_time": "2024-10-28T12:45:48.951811Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "class SumPooling(torch.nn.Module):\n",
    "    def __init__(self, dim: int | tuple[int, ...] = 1):\n",
    "        super(SumPooling, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, H: torch.Tensor):\n",
    "        # Compute sum across the specified dimension(s)\n",
    "        return H.sum(dim=self.dim)\n",
    "def custom_collate_fn(batch):\n",
    "    adjacencies, features, targets = zip(*batch)  # Unzip the batch into three lists\n",
    "    return list(adjacencies), list(features), torch.tensor(targets)\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "add7fe46-769b-4d5c-8c9a-115c877132e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:39.994333Z",
     "start_time": "2024-10-28T12:49:39.976866Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=torch.nn.functional.relu):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_features)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor):\n",
    "        # Add self-loops to the edge index\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Compute normalization coefficients\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Message passing\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        return self.activation(out)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def propagate(self, edge_index, x, norm):\n",
    "        row, col = edge_index\n",
    "        return torch.zeros_like(x).scatter_add_(0, row.unsqueeze(-1).expand(-1, x.size(1)), norm.unsqueeze(-1) * x[col])\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "4c9a35b2",
   "metadata": {},
   "source": [
    "## MolHIV\n",
    "\n",
    "Pytorch Geometric stores its graphs in a sparse format using the variable edge_index.\n",
    "We will thus need to create our own (torch) dataloader and extract the graphs into dense adjacency matrices.\n",
    "\n",
    "In terms of model accuracy, it really helped me to add an \"Atom encoding\", i.e. a one-hot-encoding of the atoms instead of just having the atomic numbers appear in the first column of the node features."
   ]
  },
  {
   "cell_type": "code",
   "id": "4abc2004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:41.083567Z",
     "start_time": "2024-10-28T12:49:41.073940Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, adjacencies, features, targets, max_nodes):\n",
    "        self.max_nodes = max_nodes\n",
    "        self.adjacencies = [pad(torch.tensor(adj, dtype=torch.float32), (0, max_nodes - adj.size(0), 0, max_nodes - adj.size(0))) for adj in adjacencies]\n",
    "        self.features = [pad(torch.tensor(feat, dtype=torch.float32), (0, 0, 0, max_nodes - feat.size(0))) for feat in features]\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adjacencies[idx], self.features[idx], self.targets[idx]\n",
    "\n",
    "    def num_features(self):\n",
    "        return self.features[0].shape[-1]\n",
    "\n",
    "    def compute_class_weights(self):\n",
    "        class_counts = torch.bincount(self.targets)\n",
    "        total_samples = len(self.targets)\n",
    "        weights = total_samples / (class_counts + 1e-6)\n",
    "        return weights\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "7e1e0711-ea5a-4c92-979a-31053adbad79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:41.094746Z",
     "start_time": "2024-10-28T12:49:41.087492Z"
    }
   },
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "def extract_graphs_and_features(dataset):\n",
    "    adjacencies = []\n",
    "    features = []\n",
    "    targets = []\n",
    "    atoms_to_index = {}  # Optional: map atom types to indices if needed\n",
    "\n",
    "    for i, graph in enumerate(dataset):\n",
    "        # Convert sparse edge_index to a dense adjacency matrix\n",
    "        adjacency_matrix = to_dense_adj(graph.edge_index).squeeze(0)\n",
    "        adjacencies.append(adjacency_matrix)\n",
    "\n",
    "        # Extract node features (e.g., atom types)\n",
    "        features.append(graph.x)\n",
    "\n",
    "        # Extract the graph label (molHIV uses binary classification)\n",
    "        targets.append(graph.y.item())\n",
    "\n",
    "        # Update atoms_to_index (assuming feature 0 in graph.x is atom type)\n",
    "        for atom_type in graph.x[:, 0].unique().tolist():\n",
    "            if atom_type not in atoms_to_index:\n",
    "                atoms_to_index[atom_type] = len(atoms_to_index)\n",
    "\n",
    "    return adjacencies, features, targets, atoms_to_index"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "8f15487e-5c77-44ad-83f9-aa9df8da20b4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Create Data Loaders for MolHIV"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1fd2530-1131-4041-882e-4e73970a6f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:50:16.762039Z",
     "start_time": "2024-10-28T12:49:41.098666Z"
    }
   },
   "source": [
    "from torch.nn.functional import pad\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def pad_collate(batch):\n",
    "    max_nodes = max(adjacency.size(0) for adjacency, _, _ in batch)  # Find the largest graph size in the batch\n",
    "\n",
    "    adjacencies = []\n",
    "    features = []\n",
    "    targets = []\n",
    "\n",
    "    for adjacency, feature, target in batch:\n",
    "        # Pad adjacency matrix and feature matrix to max_nodes size\n",
    "        padded_adj = pad(adjacency, (0, max_nodes - adjacency.size(0), 0, max_nodes - adjacency.size(0)))\n",
    "        padded_feat = pad(feature, (0, 0, 0, max_nodes - feature.size(0)))\n",
    "\n",
    "        adjacencies.append(padded_adj)\n",
    "        features.append(padded_feat)\n",
    "        targets.append(target)\n",
    "\n",
    "    # Stack padded matrices and targets\n",
    "    adjacencies = torch.stack(adjacencies)\n",
    "    features = torch.stack(features)\n",
    "    targets = torch.tensor(targets)\n",
    "\n",
    "    return adjacencies, features, targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "molHIV = PygGraphPropPredDataset(name = \"ogbg-molhiv\") \n",
    "\n",
    "\n",
    "\n",
    "split_idx = molHIV.get_idx_split() \n",
    "all_adjacencies, all_features, all_targets, atoms_to_index = extract_graphs_and_features(molHIV)\n",
    "\n",
    "max_nodes = max(adj.size(0) for adj in all_adjacencies)\n",
    "print(f\"Max nodes in dataset: {max_nodes}\")\n",
    "\n",
    "all_adjacencies = [torch.tensor(adj, dtype=torch.float32) for adj in all_adjacencies]\n",
    "all_features = [torch.tensor(feat, dtype=torch.float32) for feat in all_features]\n",
    "all_targets = torch.tensor(all_targets, dtype=torch.int64)\n",
    "# Create datasets using split_idx indices\n",
    "graph_dataset = GraphDataset(all_adjacencies, all_features, all_targets, max_nodes=max_nodes)\n",
    "train_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"train\"])\n",
    "val_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"valid\"])\n",
    "test_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"test\"])\n",
    "\n",
    "# Create subsets for training, validation, and test\n",
    "train_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"train\"])\n",
    "val_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"valid\"])\n",
    "test_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"test\"])\n",
    "\n",
    "# Create DataLoaders\n",
    "# Update DataLoaders with the custom collate function\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\Lib\\site-packages\\ogb\\graphproppred\\dataset_pyg.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max nodes in dataset: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_17988\\2221470834.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_adjacencies = [torch.tensor(adj, dtype=torch.float32) for adj in all_adjacencies]\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_17988\\2221470834.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_features = [torch.tensor(feat, dtype=torch.float32) for feat in all_features]\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_17988\\3235137515.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.adjacencies = [pad(torch.tensor(adj, dtype=torch.float32), (0, max_nodes - adj.size(0), 0, max_nodes - adj.size(0))) for adj in adjacencies]\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_17988\\3235137515.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = [pad(torch.tensor(feat, dtype=torch.float32), (0, 0, 0, max_nodes - feat.size(0))) for feat in features]\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_17988\\3235137515.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(targets, dtype=torch.long)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "db11527f",
   "metadata": {},
   "source": [
    "### Model and Training for MolHIV\n",
    "\n",
    "The evaluation of MolHIV (and all other datasets from ogb) should happen through an Evaluator. You can also try playing around with learning rate schedulers."
   ]
  },
  {
   "cell_type": "code",
   "id": "52980ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:50:16.777023Z",
     "start_time": "2024-10-28T12:50:16.764979Z"
    }
   },
   "source": [
    "evaluator = Evaluator(name='ogbg-molhiv')\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_true = list()\n",
    "    y_pred = list()\n",
    "\n",
    "    for adjacencies, features, targets in loader:\n",
    "        adjacencies, features = adjacencies.to(device), features.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(features, adjacencies)\n",
    "        y_pred.append(pred.argmax(dim=-1, keepdims=True))\n",
    "        y_true.append(targets)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0).detach().cpu()\n",
    "    y_pred = torch.cat(y_pred, dim=0).detach().cpu()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict)['rocauc']"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "00bd8864-bbbb-4a9e-a4ed-27233a9477f5",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T12:50:18.144470Z",
     "start_time": "2024-10-28T12:50:16.779964Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GraphGCN(\n",
    "    in_features=graph_dataset.num_features(),\n",
    "    hidden_dim=64,\n",
    "    out_features=2,\n",
    "    num_layers=2,\n",
    "    pooling=\"mean\"\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = graph_dataset.compute_class_weights().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Training and Evaluation Loop\n",
    "num_epochs = 50\n",
    "best_val_rocauc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for adjacencies, features, targets in train_loader:\n",
    "        # Move each graph in the batch to the device\n",
    "        adjacencies = [adj.to(device) for adj in adjacencies]\n",
    "        features = [feat.to(device) for feat in features]\n",
    "        targets = targets.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, adjacencies)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_rocauc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}, Val ROC-AUC: {val_rocauc:.4f}\")\n",
    "\n",
    "    # Save best model based on validation ROC-AUC\n",
    "    if val_rocauc > best_val_rocauc:\n",
    "        best_val_rocauc = val_rocauc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# Load the best model and evaluate on the test set\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "test_rocauc = evaluate(model, test_loader)\n",
    "print(f\"Test ROC-AUC: {test_rocauc:.4f}\")\n"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 222 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 35\u001B[0m\n\u001B[0;32m     32\u001B[0m targets \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     34\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 35\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(features, adjacencies)\n\u001B[0;32m     36\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n\u001B[0;32m     37\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[32], line 24\u001B[0m, in \u001B[0;36mGraphGCN.forward\u001B[1;34m(self, adjacencies, features)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Pass through GCN layers\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 24\u001B[0m     H \u001B[38;5;241m=\u001B[39m layer(H, adj)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Pool the node features to get a graph representation\u001B[39;00m\n\u001B[0;32m     27\u001B[0m H_pooled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling(H\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[39], line 13\u001B[0m, in \u001B[0;36mGCNLayer.forward\u001B[1;34m(self, x, edge_index)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor, edge_index: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# Add self-loops to the edge index\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m     edge_index, _ \u001B[38;5;241m=\u001B[39m add_self_loops(edge_index, num_nodes\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# Compute normalization coefficients\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     row, col \u001B[38;5;241m=\u001B[39m edge_index\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:472\u001B[0m, in \u001B[0;36madd_self_loops\u001B[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001B[0m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    470\u001B[0m     loop_index \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0\u001B[39m, N, device\u001B[38;5;241m=\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mrepeat(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 472\u001B[0m full_edge_index \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([edge_index, loop_index], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sparse:\n\u001B[0;32m    475\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m edge_attr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 222 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e82031e29e5e1e2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "346d06ddde23e2d7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
