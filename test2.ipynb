{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb719674-c334-440d-af62-1aed8c57f1ec",
   "metadata": {},
   "source": [
    "# Dense GNN implementation\n",
    "\n",
    "In this exercise we are implementing a GNN from scratch using dense matrices.\n",
    "Note that as the memory requirement of a dense matrix scales quadratically with the number of nodes in a graph, this limits us to datasets with only small graphs. \n",
    "\n",
    "We will use the following dataset molHIV.\n",
    "\n",
    "For the network we need a message-passing layer and pooling function.\n",
    "\n",
    "1. Describe the datasets in your own words. Also talk about its features and statistical properties of the graphs and labels.\n",
    "1. Implement the class GCNLayer to perform one round of message passing. You may use any variant of message passing here.\n",
    "1. Implement a pooling layer like MeanPooling or SumPooling (or both).\n",
    "1. Implement a one-hot-encoding of the atom type (this will positively affect classification performance)\n",
    "1. Implement the model class GraphGCN that builds upon your GCNLayer and Pooling layer.\n",
    "1. Create and train a GraphGCN model on MolHIV. As MOlHIV is highly imbalanced, it will make sense to adapt class weights in your loss function.\n",
    "\n",
    "For the dataset molHIV we aim to reach something like 0.64 ROC (or higher). Note that for me the training was quite unstable, so several runs got stuck at 0.5.\n",
    "\n",
    "Note: In this exercise, we use PyG only for utilities and not to build models. Feel free to edit/ignore any of the provided code as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "id": "78608f62-c77d-4f16-a924-50843e5bcc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.586938Z",
     "start_time": "2024-10-27T11:55:53.583244Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import numpy as np\n",
    "from ogb.graphproppred import PygGraphPropPredDataset,Evaluator\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "id": "906e13d0-cf25-450f-948c-c8f3fa214850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.594104Z",
     "start_time": "2024-10-27T11:55:53.588016Z"
    }
   },
   "source": [
    "# find device\n",
    "if torch.cuda.is_available(): # NVIDIA\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # apple silicon\n",
    "    device = torch.device('mps') \n",
    "else:\n",
    "    device = torch.device('cpu') # fallback\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "id": "76a3a3e8-b9cb-42d7-be0f-8c41a1304a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.599313Z",
     "start_time": "2024-10-27T11:55:53.595188Z"
    }
   },
   "source": [
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=torch.nn.functional.relu):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.activation = activation\n",
    "        self.linear = torch.nn.Linear(in_features, out_features, bias=False)\n",
    "\n",
    "    def forward(self, H: torch.Tensor, adj: torch.Tensor):\n",
    "        # Normalize adjacency matrix\n",
    "        adj = adj + torch.eye(adj.size(0)).to(adj.device)  # Add self-loops\n",
    "        D = torch.diag(torch.sum(adj, dim=1))  # Degree matrix\n",
    "        D_inv_sqrt = torch.pow(D, -0.5)\n",
    "        D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0.0\n",
    "        adj_norm = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "\n",
    "        # Apply GCN transformation\n",
    "        H = self.linear(H)\n",
    "        H = adj_norm @ H\n",
    "        if self.activation:\n",
    "            H = self.activation(H)\n",
    "        return H\n"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "id": "f07521e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.605173Z",
     "start_time": "2024-10-27T11:55:53.600324Z"
    }
   },
   "source": [
    "class MeanPooling(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, H: torch.Tensor):\n",
    "        # Since we're not provided with batch indices, we assume H contains nodes from a single graph\n",
    "        graph_embedding = H.mean(dim=0)\n",
    "        return graph_embedding\n"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "id": "0bc412b3-5648-4f1f-88a0-f5a18a27a419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.621662Z",
     "start_time": "2024-10-27T11:55:53.618111Z"
    }
   },
   "source": [
    "class SumPooling(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SumPooling, self).__init__()\n",
    "\n",
    "    def forward(self, H: torch.Tensor):\n",
    "        graph_embedding = H.sum(dim=0)\n",
    "        return graph_embedding\n"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "id": "add7fe46-769b-4d5c-8c9a-115c877132e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.636141Z",
     "start_time": "2024-10-27T11:55:53.631459Z"
    }
   },
   "source": [
    "class GraphGCN(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, hidden_features: int, num_classes: int, activation=torch.nn.functional.relu):\n",
    "        super(GraphGCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_features, hidden_features, activation)\n",
    "        self.gcn2 = GCNLayer(hidden_features, hidden_features, activation)\n",
    "        self.pool = MeanPooling()  # You can choose SumPooling() instead\n",
    "        self.classifier = torch.nn.Linear(hidden_features, num_classes)\n",
    "\n",
    "    def forward(self, H_in: torch.Tensor, adj: torch.Tensor):\n",
    "        H = self.gcn1(H_in, adj)\n",
    "        H = self.gcn2(H, adj)\n",
    "        graph_embedding = self.pool(H)\n",
    "        out = self.classifier(graph_embedding)\n",
    "        return out\n"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "id": "4c9a35b2",
   "metadata": {},
   "source": [
    "## MolHIV\n",
    "\n",
    "Pytorch Geometric stores its graphs in a sparse format using the variable edge_index.\n",
    "We will thus need to create our own (torch) dataloader and extract the graphs into dense adjacency matrices.\n",
    "\n",
    "In terms of model accuracy, it really helped me to add an \"Atom encoding\", i.e. a one-hot-encoding of the atoms instead of just having the atomic numbers appear in the first column of the node features."
   ]
  },
  {
   "cell_type": "code",
   "id": "4abc2004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.652846Z",
     "start_time": "2024-10-27T11:55:53.647501Z"
    }
   },
   "source": [
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, adjacencies, features, targets):\n",
    "        self.adjacencies = torch.tensor(adjacencies, dtype=torch.float32)\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adjacencies[idx], self.features[idx], self.targets[idx]\n",
    "\n",
    "    def num_features(self):\n",
    "        return self.features.shape[-1]\n",
    "\n",
    "    def compute_class_weights(self):\n",
    "        \"\"\"\n",
    "        Computes class weights inversely proportional to the class frequencies.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: A tensor containing the weight for each class.\n",
    "        \"\"\"\n",
    "        # Count the number of samples per class\n",
    "        class_counts = torch.bincount(self.targets)\n",
    "        num_classes = len(class_counts)\n",
    "\n",
    "        # Handle cases where a class might be missing in the dataset\n",
    "        if num_classes < 2:\n",
    "            raise ValueError(\"The dataset must have at least two classes for classification.\")\n",
    "\n",
    "        total_samples = self.targets.size(0)\n",
    "\n",
    "        # Compute class weights: weight = total_samples / (num_classes * class_count)\n",
    "        class_weights = total_samples / (num_classes * class_counts.float())\n",
    "\n",
    "        # Normalize class weights to have a mean of 1.0 (optional)\n",
    "        class_weights = class_weights * (num_classes / class_weights.sum())\n",
    "\n",
    "        return class_weights\n"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "id": "7e1e0711-ea5a-4c92-979a-31053adbad79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:53.686624Z",
     "start_time": "2024-10-27T11:55:53.679992Z"
    }
   },
   "source": [
    "def extract_graphs_and_features(dataset):\n",
    "    adjacencies = []\n",
    "    features = []\n",
    "    targets = []\n",
    "    atoms_to_index = {}  # Optional mapping if needed\n",
    "\n",
    "    # Determine the total number of unique atom types for one-hot encoding\n",
    "    all_atom_types = []\n",
    "    for data in dataset:\n",
    "        atom_types = data.x[:, 0].long()  # Adjust index if atom type is in a different column\n",
    "        all_atom_types.append(atom_types)\n",
    "    all_atom_types = torch.cat(all_atom_types)\n",
    "    num_atom_types = all_atom_types.max().item() + 1  # Assuming atom types are zero-indexed\n",
    "\n",
    "    for data in dataset:\n",
    "        # Extract node features and target labels\n",
    "        x = data.x  # Node features tensor of shape [num_nodes, num_node_features]\n",
    "        y = data.y  # Target label tensor\n",
    "\n",
    "        # One-hot encode the atom types\n",
    "        atom_types = x[:, 0].long()  # Adjust index if necessary\n",
    "        one_hot_atom_types = torch.zeros((atom_types.size(0), num_atom_types))\n",
    "        one_hot_atom_types[torch.arange(atom_types.size(0)), atom_types] = 1.0\n",
    "\n",
    "        # Optionally include other node features\n",
    "        # For simplicity, we'll use only the one-hot encoded atom types\n",
    "        features_combined = one_hot_atom_types\n",
    "\n",
    "        # Convert edge_index to a dense adjacency matrix\n",
    "        edge_index = data.edge_index  # Edge indices tensor of shape [2, num_edges]\n",
    "        num_nodes = x.size(0)\n",
    "        adj = torch.zeros((num_nodes, num_nodes), dtype=torch.float32)\n",
    "        adj[edge_index[0], edge_index[1]] = 1.0\n",
    "\n",
    "        # Append to the lists\n",
    "        adjacencies.append(adj)\n",
    "        features.append(features_combined)\n",
    "        targets.append(y.squeeze())  # Ensure targets are scalar\n",
    "\n",
    "    return adjacencies, features, targets, atoms_to_index\n"
   ],
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "id": "8f15487e-5c77-44ad-83f9-aa9df8da20b4",
   "metadata": {},
   "source": [
    "### Create Data Loaders for MolHIV"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1fd2530-1131-4041-882e-4e73970a6f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:55:59.563145Z",
     "start_time": "2024-10-27T11:55:53.691247Z"
    }
   },
   "source": [
    "batch_size = 32\n",
    "\n",
    "molHIV = PygGraphPropPredDataset(name = \"ogbg-molhiv\") \n",
    "split_idx = molHIV.get_idx_split() \n",
    "all_adjacencies, all_features, all_targets, atoms_to_index = extract_graphs_and_features(molHIV)\n",
    "all_targets = all_targets.to(torch.int64)\n",
    "\n",
    "# Create datasets using split_idx indices\n",
    "graph_dataset = GraphDataset(all_adjacencies, all_features, all_targets)\n",
    "train_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"train\"])\n",
    "val_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"valid\"])\n",
    "test_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"test\"]) \n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\Lib\\site-packages\\ogb\\graphproppred\\dataset_pyg.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[117], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m split_idx \u001B[38;5;241m=\u001B[39m molHIV\u001B[38;5;241m.\u001B[39mget_idx_split() \n\u001B[0;32m      5\u001B[0m all_adjacencies, all_features, all_targets, atoms_to_index \u001B[38;5;241m=\u001B[39m extract_graphs_and_features(molHIV)\n\u001B[1;32m----> 6\u001B[0m all_targets \u001B[38;5;241m=\u001B[39m all_targets\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mint64)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Create datasets using split_idx indices\u001B[39;00m\n\u001B[0;32m      9\u001B[0m graph_dataset \u001B[38;5;241m=\u001B[39m GraphDataset(all_adjacencies, all_features, all_targets)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "id": "db11527f",
   "metadata": {},
   "source": [
    "### Model and Training for MolHIV\n",
    "\n",
    "The evaluation of MolHIV (and all other datasets from ogb) should happen through an Evaluator. You can also try playing around with learning rate schedulers."
   ]
  },
  {
   "cell_type": "code",
   "id": "52980ac9",
   "metadata": {},
   "source": [
    "evaluator = Evaluator(name='ogbg-molhiv')\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_true = list()\n",
    "    y_pred = list()\n",
    "\n",
    "    for adjacencies, features, targets in loader:\n",
    "        adjacencies, features = adjacencies.to(device), features.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(features, adjacencies)\n",
    "        y_pred.append(pred.argmax(dim=-1, keepdims=True))\n",
    "        y_true.append(targets)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0).detach().cpu()\n",
    "    y_pred = torch.cat(y_pred, dim=0).detach().cpu()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict)['rocauc']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00bd8864-bbbb-4a9e-a4ed-27233a9477f5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Model definition and Training loop\n",
    "raise NotImplementedError"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
