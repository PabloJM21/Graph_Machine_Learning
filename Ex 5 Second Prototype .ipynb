{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:53:44.411188Z",
     "start_time": "2024-11-25T14:53:41.768143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import torch_scatter\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import to_networkx, subgraph\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# Ensure reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# TASK 1 & 2: GINE Layer with Virtual Nodes (without node_encoder)\n",
    "class GINELayerWithVN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super(GINELayerWithVN, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        self.edge_encoder = torch.nn.Linear(edge_dim, out_channels)\n",
    "        # Remove node_encoder from here\n",
    "        self.virtual_node_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.edge_encoder.weight)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "        for m in self.virtual_node_mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, vn_embed, batch):\n",
    "        # x is already encoded via node_encoder in the main model\n",
    "        x = x.float()  # Ensure x is FloatTensor\n",
    "        edge_attr = edge_attr.float()  # Ensure edge_attr is FloatTensor\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # Add virtual node embedding to node features\n",
    "        vn_expanded = vn_embed[batch]\n",
    "        x = x + vn_expanded\n",
    "\n",
    "        # Message Passing\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        # Update node embeddings\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Compute messages\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "# TASK 4: Laplacian Positional Encodings (LapPE)\n",
    "def compute_laplace_pe(data, num_eigenvec=10):\n",
    "    # Compute the graph Laplacian\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    D = torch.diag(torch.tensor(np.array(A.sum(axis=1)).flatten(), dtype=torch.float))\n",
    "    L = D - torch.tensor(A.todense(), dtype=torch.float)\n",
    "\n",
    "    # Compute eigenvectors\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(L)\n",
    "    except RuntimeError:\n",
    "        # If eigh fails, use symeig for symmetric matrices\n",
    "        eigenvalues, eigenvectors = torch.symeig(L, eigenvectors=True)\n",
    "\n",
    "    # Number of eigenvectors available (excluding the first trivial one)\n",
    "    available_eigenvec = eigenvectors.shape[1] - 1\n",
    "    actual_num_eigenvec = min(num_eigenvec, available_eigenvec)\n",
    "\n",
    "    # Take the first 'actual_num_eigenvec' eigenvectors (excluding the zero eigenvalue)\n",
    "    eigenvectors = eigenvectors[:, 1:1 + actual_num_eigenvec]\n",
    "\n",
    "    # If actual_num_eigenvec < num_eigenvec, pad with zeros\n",
    "    if actual_num_eigenvec < num_eigenvec:\n",
    "        pad_size = num_eigenvec - actual_num_eigenvec\n",
    "        padding = torch.zeros(eigenvectors.shape[0], pad_size).to(device)\n",
    "        eigenvectors = torch.cat([eigenvectors, padding], dim=1)\n",
    "\n",
    "    return eigenvectors  # Shape: (num_nodes, num_eigenvec)\n",
    "\n",
    "# TASK 4: Random Walk Structural Embeddings (RWSE)\n",
    "def compute_rwse(data, walk_length=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    rw_features = []\n",
    "    for _ in range(walk_length):\n",
    "        A = A.dot(A)\n",
    "        diag = np.diag(A.todense())\n",
    "        rw_features.append(torch.tensor(diag, dtype=torch.float))\n",
    "    rwse = torch.stack(rw_features, dim=1)  # (num_nodes, walk_length)\n",
    "    return rwse  # Shape: (num_nodes, walk_length)\n",
    "\n",
    "# TASK 4: SignNet to ensure sign invariance\n",
    "class SignNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(SignNet, self).__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.phi(x) + self.phi(-x)\n",
    "\n",
    "# Graph Transformer Layer\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, dropout=0.1):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=in_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(out_dim, in_dim)\n",
    "        self.norm1 = nn.LayerNorm(in_dim)\n",
    "        self.norm2 = nn.LayerNorm(in_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (sequence_length, batch_size, embed_dim)\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = x + attn_output\n",
    "        x = self.norm1(x)\n",
    "        linear_output = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        x = x + linear_output\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "# Updated GNN Model with Virtual Node, GINE Layers, and Graph Transformer\n",
    "class GNNWithVirtualNodeAndGINEAndTransformer(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10):\n",
    "        super(GNNWithVirtualNodeAndGINEAndTransformer, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        # Node Encoder (moved outside GINE layers)\n",
    "        self.node_encoder = nn.Linear(in_features, hidden_features)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(GINELayerWithVN(\n",
    "                in_channels=hidden_features,\n",
    "                out_channels=hidden_features,\n",
    "                edge_dim=edge_attr_dim\n",
    "            ))\n",
    "\n",
    "        self.virtual_node_embedding = torch.nn.Embedding(1, hidden_features)\n",
    "        torch.nn.init.constant_(self.virtual_node_embedding.weight.data, 0)\n",
    "\n",
    "        self.mlp_virtual_node = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Positional Encodings\n",
    "        self.lap_pe_dim = lap_pe_dim\n",
    "        self.rwse_dim = rwse_dim\n",
    "        self.lap_pe_linear = nn.Linear(hidden_features, hidden_features)  # Corrected input dimension\n",
    "        self.rwse_linear = nn.Linear(rwse_dim, hidden_features)\n",
    "        self.signnet = SignNet(lap_pe_dim, hidden_features)\n",
    "\n",
    "        # Graph Transformer\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(hidden_features, hidden_features) for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, data):\n",
    "        # Apply node_encoder first\n",
    "        x = self.node_encoder(x)  # [num_nodes, hidden_features]\n",
    "        print(f\"After node_encoder, x shape: {x.shape}\")  # Debugging\n",
    "\n",
    "        # Initialize pos_enc tensor\n",
    "        pos_enc = torch.zeros_like(x).to(device)  # [num_nodes, hidden_features]\n",
    "        print(f\"Initialized pos_enc shape: {pos_enc.shape}\")  # Debugging\n",
    "\n",
    "        # Iterate over each graph in the batch\n",
    "        num_graphs = batch.max().item() + 1\n",
    "        for graph_id in range(num_graphs):\n",
    "            mask = (batch == graph_id)\n",
    "            num_nodes_graph = mask.sum().item()\n",
    "            print(f\"Graph ID: {graph_id}, Num Nodes: {num_nodes_graph}\")  # Debugging\n",
    "\n",
    "            # Extract node indices for the current graph\n",
    "            node_idx = torch.where(batch == graph_id)[0]\n",
    "\n",
    "            # Extract subgraph using pyg.utils.subgraph\n",
    "            sub_edge_index, sub_edge_attr = pyg.utils.subgraph(\n",
    "                node_idx,\n",
    "                edge_index,\n",
    "                edge_attr,\n",
    "                relabel_nodes=True,\n",
    "                num_nodes=x.size(0)  # Ensures all nodes are considered\n",
    "            )\n",
    "\n",
    "            # Create sub_data\n",
    "            sub_data = pyg.data.Data(\n",
    "                x=x[node_idx],\n",
    "                edge_index=sub_edge_index,\n",
    "                edge_attr=sub_edge_attr\n",
    "            )\n",
    "\n",
    "            # Compute Positional Encodings for the sub-graph\n",
    "            lap_pe = compute_laplace_pe(sub_data, num_eigenvec=self.lap_pe_dim).to(device)  # [num_nodes_graph, lap_pe_dim]\n",
    "            rwse = compute_rwse(sub_data, walk_length=self.rwse_dim).to(device)  # [num_nodes_graph, walk_length]\n",
    "            print(f\"LapPE shape: {lap_pe.shape}, RWSE shape: {rwse.shape}\")  # Debugging\n",
    "\n",
    "            # Apply SignNet to LapPE\n",
    "            lap_pe = self.signnet(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "            print(f\"After SignNet LapPE shape: {lap_pe.shape}\")  # Debugging\n",
    "\n",
    "            # Linear transformation\n",
    "            lap_pe = self.lap_pe_linear(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "            rwse = self.rwse_linear(rwse)        # [num_nodes_graph, hidden_features]\n",
    "            print(f\"After linear transformation LapPE shape: {lap_pe.shape}, RWSE shape: {rwse.shape}\")  # Debugging\n",
    "\n",
    "            # Combine positional encodings\n",
    "            graph_pos_enc = lap_pe + rwse  # [num_nodes_graph, hidden_features]\n",
    "            print(f\"Graph Positional Encoding shape: {graph_pos_enc.shape}\")  # Debugging\n",
    "\n",
    "            # Assign to pos_enc\n",
    "            pos_enc[node_idx] = graph_pos_enc  # [num_nodes, hidden_features]\n",
    "            print(f\"Assigned pos_enc for graph {graph_id}\")  # Debugging\n",
    "\n",
    "        # Add positional encodings to node features\n",
    "        x = x + pos_enc  # [num_nodes, hidden_features]\n",
    "        print(f\"After adding pos_enc, x shape: {x.shape}\")  # Debugging\n",
    "\n",
    "        # Initialize virtual node embedding\n",
    "        batch_size = num_graphs\n",
    "        vn_embed = self.virtual_node_embedding.weight.repeat(batch_size, 1)  # [batch_size, hidden_features]\n",
    "        print(f\"Virtual node embedding shape: {vn_embed.shape}\")  # Debugging\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_attr, vn_embed, batch)  # [num_nodes, hidden_features]\n",
    "            x = F.relu(x)\n",
    "            print(f\"After conv and ReLU, x shape: {x.shape}\")  # Debugging\n",
    "\n",
    "            # Update virtual node embedding\n",
    "            vn_aggr = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "            print(f\"Virtual node aggregation shape: {vn_aggr.shape}\")  # Debugging\n",
    "            vn_embed = vn_embed + self.mlp_virtual_node(vn_aggr)  # [batch_size, hidden_features]\n",
    "            print(f\"Updated virtual node embedding shape: {vn_embed.shape}\")  # Debugging\n",
    "\n",
    "        # Prepare for Graph Transformer\n",
    "        #x = x.transpose(0, 1)  # [num_nodes, batch_size, hidden_features]\n",
    "        print(f\"Before Transformer, x shape: {x.shape}\")  # Debugging\n",
    "        for idx, transformer in enumerate(self.transformer_layers):\n",
    "            x = transformer(x)  # [num_nodes, batch_size, hidden_features]\n",
    "            print(f\"After Transformer layer {idx+1}, x shape: {x.shape}\")  # Debugging\n",
    "        x = x.transpose(0, 1)  # [batch_size, num_nodes, hidden_features]\n",
    "        print(f\"After Transformer, x shape: {x.shape}\")  # Debugging\n",
    "\n",
    "        # Graph-level readout\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "        print(f\"After global_mean_pool, x shape: {x.shape}\")  # Debugging\n",
    "        x = self.fc(x)  # [batch_size, out_features]\n",
    "        print(f\"After final fc layer, x shape: {x.shape}\")  # Debugging\n",
    "        return x\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        batch.x = batch.x.float()  # Convert node features to float\n",
    "        batch.edge_attr = batch.edge_attr.float()  # Convert edge attributes to float\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch)\n",
    "        loss = loss_fn(out, batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / len(loader)\n",
    "    return average_loss\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            batch.x = batch.x.float()  # Convert node features to float\n",
    "            batch.edge_attr = batch.edge_attr.float()  # Convert edge attributes to float\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch)\n",
    "            y_pred.append(out.cpu())\n",
    "            y_true.append(batch.y.cpu())\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "    # Compute per-class AP\n",
    "    ap_per_class = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        try:\n",
    "            ap = average_precision_score(y_true[:, i], y_pred[:, i])\n",
    "        except ValueError:\n",
    "            ap = 0.0  # Handle cases where a class has no positive samples\n",
    "        ap_per_class.append(ap)\n",
    "    mean_ap = np.mean(ap_per_class)\n",
    "    return mean_ap\n",
    "\n",
    "def plot_results(epochs, train_losses, val_aps, learning_rates=None):\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Training_Loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation AP Score\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs_range, val_aps, label='Validation AP Score', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Precision Score')\n",
    "    plt.title('Validation AP Score over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Validation_AP_Score.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Learning Rate if provided\n",
    "    if learning_rates is not None:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(epochs_range, learning_rates, label='Learning Rate', color='green')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.title('Learning Rate over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig('Learning_Rate.png')\n",
    "        plt.show()\n",
    "\n",
    "def main(epochs=100, lr=0.001, hidden_features=256):\n",
    "    # Compute edge_attr_dim and num_tasks from the dataset\n",
    "    edge_attr_dim = dataset[0].edge_attr.shape[1]\n",
    "    num_tasks = dataset[0].y.shape[-1]\n",
    "\n",
    "    # Initialize the model, optimizer, and loss function\n",
    "    model = GNNWithVirtualNodeAndGINEAndTransformer(\n",
    "        in_features=dataset.num_node_features,\n",
    "        hidden_features=hidden_features,\n",
    "        out_features=num_tasks,\n",
    "        edge_attr_dim=edge_attr_dim,\n",
    "        num_layers=5,  # Increased depth as per the paper's suggestion\n",
    "        lap_pe_dim=10,\n",
    "        rwse_dim=10\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=10)\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Lists to store losses and AP scores\n",
    "    train_losses = []\n",
    "    val_aps = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn)\n",
    "        val_ap = evaluate(model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_aps.append(val_ap)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation AP Score: {val_ap:.4f}, Learning Rate: {current_lr:.6f}\")\n",
    "        scheduler.step(val_ap)\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_ap = evaluate(model, test_loader)\n",
    "    print(f\"Test AP Score: {test_ap:.4f}\")\n",
    "\n",
    "    # Plotting the results\n",
    "    plot_results(epochs, train_losses, val_aps, learning_rates)\n",
    "\n",
    "# Task 4: Draw the molecule represented by peptides_train[0]\n",
    "def draw_molecule(data, def_col=0):\n",
    "    G = pyg.utils.to_networkx(data, to_undirected=True)\n",
    "    node_features = data.x.numpy()\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    edge_attr = data.edge_attr.numpy()\n",
    "    bond_types = edge_attr[:, 0].astype(int)\n",
    "    atom_types = None\n",
    "    atom_type_indices = None\n",
    "    for i, (u, v) in enumerate(zip(edge_index[0], edge_index[1])):\n",
    "        G.edges[u, v]['bond_type'] = bond_types[i]\n",
    "    if def_col == 0:\n",
    "        atom_types = {\n",
    "            5: 'C',\n",
    "            6: 'N',\n",
    "            7: 'O',\n",
    "        }\n",
    "        atom_type_indices = node_features[:, def_col].astype(int)\n",
    "    elif def_col == 2:\n",
    "        atom_types = {4: 'C', 3: 'O', 1: 'N'}\n",
    "        atom_type_indices = node_features[:, def_col].astype(int)\n",
    "    elif def_col == 4:\n",
    "        atom_types = {1: 'C', 0: 'O', 2: 'N'}\n",
    "        atom_type_indices = node_features[:, def_col].astype(int)\n",
    "    bond_color_mapping = {\n",
    "        0: 'black',\n",
    "        1: 'blue',\n",
    "        3: 'red',\n",
    "    }\n",
    "    edges = list(G.edges())\n",
    "    edge_colors = []\n",
    "    for u, v in edges:\n",
    "        bond_type = G.edges[u, v]['bond_type']\n",
    "        color = bond_color_mapping.get(bond_type, 'green')\n",
    "        edge_colors.append(color)\n",
    "    labels = {i: atom_types.get(atom_type_indices[i], 'X') for i in range(atom_type_indices.shape[0])}\n",
    "    size=12\n",
    "    plt.figure(figsize=(size, size))\n",
    "    pos = nx.kamada_kawai_layout(G, scale=5)\n",
    "    nx.draw(\n",
    "        G, pos,\n",
    "        with_labels=False,\n",
    "        node_size=50,\n",
    "        node_color='lightblue',\n",
    "        edgelist=edges,\n",
    "        edge_color=edge_colors,\n",
    "        width=1.5\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        labels=labels,\n",
    "        font_size=6,\n",
    "        font_weight='bold'\n",
    "    )\n",
    "    plt.title('Molecule Visualization of peptides_train[0]')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('Molecule_Visualization.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset and create data loaders\n",
    "    # Replace LRGBDataset with an appropriate dataset loader if needed\n",
    "    # Here, I'll assume you're using a custom dataset similar to TUDataset\n",
    "    # For demonstration, let's use TUDataset's Cora dataset if \"Peptides-func\" is not available\n",
    "\n",
    "    try:\n",
    "        dataset = pyg.datasets.LRGBDataset(root='dataset/peptides-func', name=\"Peptides-func\")\n",
    "    except AttributeError:\n",
    "        # If LRGBDataset is not available, use a placeholder\n",
    "        # Replace this with the actual dataset loader you're using\n",
    "        print(\"LRGBDataset not found. Please replace with the actual dataset loader.\")\n",
    "        dataset = TUDataset(root='dataset/Cora', name='Cora')  # Placeholder\n",
    "\n",
    "    # Check if dataset has splits; if not, create them manually\n",
    "    if hasattr(dataset, 'train_val_test_idx'):\n",
    "        peptides_train = dataset[dataset.train_val_test_idx['train']]\n",
    "        peptides_val = dataset[dataset.train_val_test_idx['val']]\n",
    "        peptides_test = dataset[dataset.train_val_test_idx['test']]\n",
    "    else:\n",
    "        # Create train, val, test splits manually\n",
    "        num_train = int(0.8 * len(dataset))\n",
    "        num_val = int(0.1 * len(dataset))\n",
    "        num_test = len(dataset) - num_train - num_val\n",
    "        peptides_train, peptides_val, peptides_test = torch.utils.data.random_split(dataset, [num_train, num_val, num_test])\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = pyg.loader.DataLoader(peptides_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = pyg.loader.DataLoader(peptides_val, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = pyg.loader.DataLoader(peptides_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Check number of classes and label distribution\n",
    "    if hasattr(dataset, 'num_tasks'):\n",
    "        num_classes = dataset.num_tasks\n",
    "    elif hasattr(dataset, 'num_classes'):\n",
    "        num_classes = dataset.num_classes\n",
    "    else:\n",
    "        # Assume binary classification if not specified\n",
    "        num_classes = 1\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    all_labels = np.concatenate([data.y.numpy() for data in dataset], axis=0)\n",
    "    label_distribution = np.mean(all_labels, axis=0)\n",
    "    print(f\"Label distribution: {label_distribution}\")\n",
    "\n",
    "    # Run the main training loop\n",
    "    main(epochs=300, lr=0.001, hidden_features=128)\n",
    "\n",
    "    # Draw the molecule for Task 4\n",
    "    if len(peptides_train) > 0:\n",
    "        draw_molecule(peptides_train[0])\n",
    "    else:\n",
    "        print(\"Training set is empty. Cannot draw a molecule.\")\n"
   ],
   "id": "818a486a6ed6da62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 10\n",
      "Label distribution: [0.08884393 0.03540881 0.06419571 0.06226432 0.6272418  0.19755358\n",
      " 0.10687023 0.18412581 0.01995769 0.2598179 ]\n",
      "After node_encoder, x shape: torch.Size([4090, 128])\n",
      "Initialized pos_enc shape: torch.Size([4090, 128])\n",
      "Graph ID: 0, Num Nodes: 96\n",
      "LapPE shape: torch.Size([96, 10]), RWSE shape: torch.Size([96, 10])\n",
      "After SignNet LapPE shape: torch.Size([96, 128])\n",
      "After linear transformation LapPE shape: torch.Size([96, 128]), RWSE shape: torch.Size([96, 128])\n",
      "Graph Positional Encoding shape: torch.Size([96, 128])\n",
      "Assigned pos_enc for graph 0\n",
      "Graph ID: 1, Num Nodes: 133\n",
      "LapPE shape: torch.Size([133, 10]), RWSE shape: torch.Size([133, 10])\n",
      "After SignNet LapPE shape: torch.Size([133, 128])\n",
      "After linear transformation LapPE shape: torch.Size([133, 128]), RWSE shape: torch.Size([133, 128])\n",
      "Graph Positional Encoding shape: torch.Size([133, 128])\n",
      "Assigned pos_enc for graph 1\n",
      "Graph ID: 2, Num Nodes: 50\n",
      "LapPE shape: torch.Size([50, 10]), RWSE shape: torch.Size([50, 10])\n",
      "After SignNet LapPE shape: torch.Size([50, 128])\n",
      "After linear transformation LapPE shape: torch.Size([50, 128]), RWSE shape: torch.Size([50, 128])\n",
      "Graph Positional Encoding shape: torch.Size([50, 128])\n",
      "Assigned pos_enc for graph 2\n",
      "Graph ID: 3, Num Nodes: 143\n",
      "LapPE shape: torch.Size([143, 10]), RWSE shape: torch.Size([143, 10])\n",
      "After SignNet LapPE shape: torch.Size([143, 128])\n",
      "After linear transformation LapPE shape: torch.Size([143, 128]), RWSE shape: torch.Size([143, 128])\n",
      "Graph Positional Encoding shape: torch.Size([143, 128])\n",
      "Assigned pos_enc for graph 3\n",
      "Graph ID: 4, Num Nodes: 79\n",
      "LapPE shape: torch.Size([79, 10]), RWSE shape: torch.Size([79, 10])\n",
      "After SignNet LapPE shape: torch.Size([79, 128])\n",
      "After linear transformation LapPE shape: torch.Size([79, 128]), RWSE shape: torch.Size([79, 128])\n",
      "Graph Positional Encoding shape: torch.Size([79, 128])\n",
      "Assigned pos_enc for graph 4\n",
      "Graph ID: 5, Num Nodes: 114\n",
      "LapPE shape: torch.Size([114, 10]), RWSE shape: torch.Size([114, 10])\n",
      "After SignNet LapPE shape: torch.Size([114, 128])\n",
      "After linear transformation LapPE shape: torch.Size([114, 128]), RWSE shape: torch.Size([114, 128])\n",
      "Graph Positional Encoding shape: torch.Size([114, 128])\n",
      "Assigned pos_enc for graph 5\n",
      "Graph ID: 6, Num Nodes: 69\n",
      "LapPE shape: torch.Size([69, 10]), RWSE shape: torch.Size([69, 10])\n",
      "After SignNet LapPE shape: torch.Size([69, 128])\n",
      "After linear transformation LapPE shape: torch.Size([69, 128]), RWSE shape: torch.Size([69, 128])\n",
      "Graph Positional Encoding shape: torch.Size([69, 128])\n",
      "Assigned pos_enc for graph 6\n",
      "Graph ID: 7, Num Nodes: 64\n",
      "LapPE shape: torch.Size([64, 10]), RWSE shape: torch.Size([64, 10])\n",
      "After SignNet LapPE shape: torch.Size([64, 128])\n",
      "After linear transformation LapPE shape: torch.Size([64, 128]), RWSE shape: torch.Size([64, 128])\n",
      "Graph Positional Encoding shape: torch.Size([64, 128])\n",
      "Assigned pos_enc for graph 7\n",
      "Graph ID: 8, Num Nodes: 118\n",
      "LapPE shape: torch.Size([118, 10]), RWSE shape: torch.Size([118, 10])\n",
      "After SignNet LapPE shape: torch.Size([118, 128])\n",
      "After linear transformation LapPE shape: torch.Size([118, 128]), RWSE shape: torch.Size([118, 128])\n",
      "Graph Positional Encoding shape: torch.Size([118, 128])\n",
      "Assigned pos_enc for graph 8\n",
      "Graph ID: 9, Num Nodes: 129\n",
      "LapPE shape: torch.Size([129, 10]), RWSE shape: torch.Size([129, 10])\n",
      "After SignNet LapPE shape: torch.Size([129, 128])\n",
      "After linear transformation LapPE shape: torch.Size([129, 128]), RWSE shape: torch.Size([129, 128])\n",
      "Graph Positional Encoding shape: torch.Size([129, 128])\n",
      "Assigned pos_enc for graph 9\n",
      "Graph ID: 10, Num Nodes: 124\n",
      "LapPE shape: torch.Size([124, 10]), RWSE shape: torch.Size([124, 10])\n",
      "After SignNet LapPE shape: torch.Size([124, 128])\n",
      "After linear transformation LapPE shape: torch.Size([124, 128]), RWSE shape: torch.Size([124, 128])\n",
      "Graph Positional Encoding shape: torch.Size([124, 128])\n",
      "Assigned pos_enc for graph 10\n",
      "Graph ID: 11, Num Nodes: 84\n",
      "LapPE shape: torch.Size([84, 10]), RWSE shape: torch.Size([84, 10])\n",
      "After SignNet LapPE shape: torch.Size([84, 128])\n",
      "After linear transformation LapPE shape: torch.Size([84, 128]), RWSE shape: torch.Size([84, 128])\n",
      "Graph Positional Encoding shape: torch.Size([84, 128])\n",
      "Assigned pos_enc for graph 11\n",
      "Graph ID: 12, Num Nodes: 131\n",
      "LapPE shape: torch.Size([131, 10]), RWSE shape: torch.Size([131, 10])\n",
      "After SignNet LapPE shape: torch.Size([131, 128])\n",
      "After linear transformation LapPE shape: torch.Size([131, 128]), RWSE shape: torch.Size([131, 128])\n",
      "Graph Positional Encoding shape: torch.Size([131, 128])\n",
      "Assigned pos_enc for graph 12\n",
      "Graph ID: 13, Num Nodes: 200\n",
      "LapPE shape: torch.Size([200, 10]), RWSE shape: torch.Size([200, 10])\n",
      "After SignNet LapPE shape: torch.Size([200, 128])\n",
      "After linear transformation LapPE shape: torch.Size([200, 128]), RWSE shape: torch.Size([200, 128])\n",
      "Graph Positional Encoding shape: torch.Size([200, 128])\n",
      "Assigned pos_enc for graph 13\n",
      "Graph ID: 14, Num Nodes: 15\n",
      "LapPE shape: torch.Size([15, 10]), RWSE shape: torch.Size([15, 10])\n",
      "After SignNet LapPE shape: torch.Size([15, 128])\n",
      "After linear transformation LapPE shape: torch.Size([15, 128]), RWSE shape: torch.Size([15, 128])\n",
      "Graph Positional Encoding shape: torch.Size([15, 128])\n",
      "Assigned pos_enc for graph 14\n",
      "Graph ID: 15, Num Nodes: 92\n",
      "LapPE shape: torch.Size([92, 10]), RWSE shape: torch.Size([92, 10])\n",
      "After SignNet LapPE shape: torch.Size([92, 128])\n",
      "After linear transformation LapPE shape: torch.Size([92, 128]), RWSE shape: torch.Size([92, 128])\n",
      "Graph Positional Encoding shape: torch.Size([92, 128])\n",
      "Assigned pos_enc for graph 15\n",
      "Graph ID: 16, Num Nodes: 286\n",
      "LapPE shape: torch.Size([286, 10]), RWSE shape: torch.Size([286, 10])\n",
      "After SignNet LapPE shape: torch.Size([286, 128])\n",
      "After linear transformation LapPE shape: torch.Size([286, 128]), RWSE shape: torch.Size([286, 128])\n",
      "Graph Positional Encoding shape: torch.Size([286, 128])\n",
      "Assigned pos_enc for graph 16\n",
      "Graph ID: 17, Num Nodes: 156\n",
      "LapPE shape: torch.Size([156, 10]), RWSE shape: torch.Size([156, 10])\n",
      "After SignNet LapPE shape: torch.Size([156, 128])\n",
      "After linear transformation LapPE shape: torch.Size([156, 128]), RWSE shape: torch.Size([156, 128])\n",
      "Graph Positional Encoding shape: torch.Size([156, 128])\n",
      "Assigned pos_enc for graph 17\n",
      "Graph ID: 18, Num Nodes: 173\n",
      "LapPE shape: torch.Size([173, 10]), RWSE shape: torch.Size([173, 10])\n",
      "After SignNet LapPE shape: torch.Size([173, 128])\n",
      "After linear transformation LapPE shape: torch.Size([173, 128]), RWSE shape: torch.Size([173, 128])\n",
      "Graph Positional Encoding shape: torch.Size([173, 128])\n",
      "Assigned pos_enc for graph 18\n",
      "Graph ID: 19, Num Nodes: 224\n",
      "LapPE shape: torch.Size([224, 10]), RWSE shape: torch.Size([224, 10])\n",
      "After SignNet LapPE shape: torch.Size([224, 128])\n",
      "After linear transformation LapPE shape: torch.Size([224, 128]), RWSE shape: torch.Size([224, 128])\n",
      "Graph Positional Encoding shape: torch.Size([224, 128])\n",
      "Assigned pos_enc for graph 19\n",
      "Graph ID: 20, Num Nodes: 120\n",
      "LapPE shape: torch.Size([120, 10]), RWSE shape: torch.Size([120, 10])\n",
      "After SignNet LapPE shape: torch.Size([120, 128])\n",
      "After linear transformation LapPE shape: torch.Size([120, 128]), RWSE shape: torch.Size([120, 128])\n",
      "Graph Positional Encoding shape: torch.Size([120, 128])\n",
      "Assigned pos_enc for graph 20\n",
      "Graph ID: 21, Num Nodes: 176\n",
      "LapPE shape: torch.Size([176, 10]), RWSE shape: torch.Size([176, 10])\n",
      "After SignNet LapPE shape: torch.Size([176, 128])\n",
      "After linear transformation LapPE shape: torch.Size([176, 128]), RWSE shape: torch.Size([176, 128])\n",
      "Graph Positional Encoding shape: torch.Size([176, 128])\n",
      "Assigned pos_enc for graph 21\n",
      "Graph ID: 22, Num Nodes: 50\n",
      "LapPE shape: torch.Size([50, 10]), RWSE shape: torch.Size([50, 10])\n",
      "After SignNet LapPE shape: torch.Size([50, 128])\n",
      "After linear transformation LapPE shape: torch.Size([50, 128]), RWSE shape: torch.Size([50, 128])\n",
      "Graph Positional Encoding shape: torch.Size([50, 128])\n",
      "Assigned pos_enc for graph 22\n",
      "Graph ID: 23, Num Nodes: 133\n",
      "LapPE shape: torch.Size([133, 10]), RWSE shape: torch.Size([133, 10])\n",
      "After SignNet LapPE shape: torch.Size([133, 128])\n",
      "After linear transformation LapPE shape: torch.Size([133, 128]), RWSE shape: torch.Size([133, 128])\n",
      "Graph Positional Encoding shape: torch.Size([133, 128])\n",
      "Assigned pos_enc for graph 23\n",
      "Graph ID: 24, Num Nodes: 106\n",
      "LapPE shape: torch.Size([106, 10]), RWSE shape: torch.Size([106, 10])\n",
      "After SignNet LapPE shape: torch.Size([106, 128])\n",
      "After linear transformation LapPE shape: torch.Size([106, 128]), RWSE shape: torch.Size([106, 128])\n",
      "Graph Positional Encoding shape: torch.Size([106, 128])\n",
      "Assigned pos_enc for graph 24\n",
      "Graph ID: 25, Num Nodes: 78\n",
      "LapPE shape: torch.Size([78, 10]), RWSE shape: torch.Size([78, 10])\n",
      "After SignNet LapPE shape: torch.Size([78, 128])\n",
      "After linear transformation LapPE shape: torch.Size([78, 128]), RWSE shape: torch.Size([78, 128])\n",
      "Graph Positional Encoding shape: torch.Size([78, 128])\n",
      "Assigned pos_enc for graph 25\n",
      "Graph ID: 26, Num Nodes: 71\n",
      "LapPE shape: torch.Size([71, 10]), RWSE shape: torch.Size([71, 10])\n",
      "After SignNet LapPE shape: torch.Size([71, 128])\n",
      "After linear transformation LapPE shape: torch.Size([71, 128]), RWSE shape: torch.Size([71, 128])\n",
      "Graph Positional Encoding shape: torch.Size([71, 128])\n",
      "Assigned pos_enc for graph 26\n",
      "Graph ID: 27, Num Nodes: 191\n",
      "LapPE shape: torch.Size([191, 10]), RWSE shape: torch.Size([191, 10])\n",
      "After SignNet LapPE shape: torch.Size([191, 128])\n",
      "After linear transformation LapPE shape: torch.Size([191, 128]), RWSE shape: torch.Size([191, 128])\n",
      "Graph Positional Encoding shape: torch.Size([191, 128])\n",
      "Assigned pos_enc for graph 27\n",
      "Graph ID: 28, Num Nodes: 90\n",
      "LapPE shape: torch.Size([90, 10]), RWSE shape: torch.Size([90, 10])\n",
      "After SignNet LapPE shape: torch.Size([90, 128])\n",
      "After linear transformation LapPE shape: torch.Size([90, 128]), RWSE shape: torch.Size([90, 128])\n",
      "Graph Positional Encoding shape: torch.Size([90, 128])\n",
      "Assigned pos_enc for graph 28\n",
      "Graph ID: 29, Num Nodes: 301\n",
      "LapPE shape: torch.Size([301, 10]), RWSE shape: torch.Size([301, 10])\n",
      "After SignNet LapPE shape: torch.Size([301, 128])\n",
      "After linear transformation LapPE shape: torch.Size([301, 128]), RWSE shape: torch.Size([301, 128])\n",
      "Graph Positional Encoding shape: torch.Size([301, 128])\n",
      "Assigned pos_enc for graph 29\n",
      "Graph ID: 30, Num Nodes: 163\n",
      "LapPE shape: torch.Size([163, 10]), RWSE shape: torch.Size([163, 10])\n",
      "After SignNet LapPE shape: torch.Size([163, 128])\n",
      "After linear transformation LapPE shape: torch.Size([163, 128]), RWSE shape: torch.Size([163, 128])\n",
      "Graph Positional Encoding shape: torch.Size([163, 128])\n",
      "Assigned pos_enc for graph 30\n",
      "Graph ID: 31, Num Nodes: 131\n",
      "LapPE shape: torch.Size([131, 10]), RWSE shape: torch.Size([131, 10])\n",
      "After SignNet LapPE shape: torch.Size([131, 128])\n",
      "After linear transformation LapPE shape: torch.Size([131, 128]), RWSE shape: torch.Size([131, 128])\n",
      "Graph Positional Encoding shape: torch.Size([131, 128])\n",
      "Assigned pos_enc for graph 31\n",
      "After adding pos_enc, x shape: torch.Size([4090, 128])\n",
      "Virtual node embedding shape: torch.Size([32, 128])\n",
      "After conv and ReLU, x shape: torch.Size([4090, 128])\n",
      "Virtual node aggregation shape: torch.Size([32, 128])\n",
      "Updated virtual node embedding shape: torch.Size([32, 128])\n",
      "After conv and ReLU, x shape: torch.Size([4090, 128])\n",
      "Virtual node aggregation shape: torch.Size([32, 128])\n",
      "Updated virtual node embedding shape: torch.Size([32, 128])\n",
      "After conv and ReLU, x shape: torch.Size([4090, 128])\n",
      "Virtual node aggregation shape: torch.Size([32, 128])\n",
      "Updated virtual node embedding shape: torch.Size([32, 128])\n",
      "After conv and ReLU, x shape: torch.Size([4090, 128])\n",
      "Virtual node aggregation shape: torch.Size([32, 128])\n",
      "Updated virtual node embedding shape: torch.Size([32, 128])\n",
      "After conv and ReLU, x shape: torch.Size([4090, 128])\n",
      "Virtual node aggregation shape: torch.Size([32, 128])\n",
      "Updated virtual node embedding shape: torch.Size([32, 128])\n",
      "Before Transformer, x shape: torch.Size([4090, 128])\n",
      "After Transformer layer 1, x shape: torch.Size([4090, 128])\n",
      "After Transformer layer 2, x shape: torch.Size([4090, 128])\n",
      "After Transformer layer 3, x shape: torch.Size([4090, 128])\n",
      "After Transformer, x shape: torch.Size([128, 4090])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [4090] to be smaller than self [32] apart from dimension 0 and to be smaller size than src [128]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 515\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLabel distribution: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel_distribution\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    514\u001B[0m \u001B[38;5;66;03m# Run the main training loop\u001B[39;00m\n\u001B[1;32m--> 515\u001B[0m main(epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, hidden_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m)\n\u001B[0;32m    517\u001B[0m \u001B[38;5;66;03m# Draw the molecule for Task 4\u001B[39;00m\n\u001B[0;32m    518\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(peptides_train) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[7], line 394\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(epochs, lr, hidden_features)\u001B[0m\n\u001B[0;32m    391\u001B[0m learning_rates \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m--> 394\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train(model, train_loader, optimizer, loss_fn)\n\u001B[0;32m    395\u001B[0m     val_ap \u001B[38;5;241m=\u001B[39m evaluate(model, val_loader)\n\u001B[0;32m    396\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n",
      "Cell \u001B[1;32mIn[7], line 297\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, loader, optimizer, loss_fn)\u001B[0m\n\u001B[0;32m    295\u001B[0m batch\u001B[38;5;241m.\u001B[39medge_attr \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39medge_attr\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# Convert edge attributes to float\u001B[39;00m\n\u001B[0;32m    296\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 297\u001B[0m out \u001B[38;5;241m=\u001B[39m model(batch\u001B[38;5;241m.\u001B[39mx, batch\u001B[38;5;241m.\u001B[39medge_index, batch\u001B[38;5;241m.\u001B[39medge_attr, batch\u001B[38;5;241m.\u001B[39mbatch, batch)\n\u001B[0;32m    298\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(out, batch\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[0;32m    299\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[7], line 282\u001B[0m, in \u001B[0;36mGNNWithVirtualNodeAndGINEAndTransformer.forward\u001B[1;34m(self, x, edge_index, edge_attr, batch, data)\u001B[0m\n\u001B[0;32m    279\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAfter Transformer, x shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Debugging\u001B[39;00m\n\u001B[0;32m    281\u001B[0m \u001B[38;5;66;03m# Graph-level readout\u001B[39;00m\n\u001B[1;32m--> 282\u001B[0m x \u001B[38;5;241m=\u001B[39m global_mean_pool(x, batch)  \u001B[38;5;66;03m# [batch_size, hidden_features]\u001B[39;00m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAfter global_mean_pool, x shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Debugging\u001B[39;00m\n\u001B[0;32m    284\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(x)  \u001B[38;5;66;03m# [batch_size, out_features]\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch_geometric\\nn\\pool\\glob.py:63\u001B[0m, in \u001B[0;36mglobal_mean_pool\u001B[1;34m(x, batch, size)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39mdim, keepdim\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scatter(x, batch, dim\u001B[38;5;241m=\u001B[39mdim, dim_size\u001B[38;5;241m=\u001B[39msize, reduce\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch_geometric\\utils\\_scatter.py:79\u001B[0m, in \u001B[0;36mscatter\u001B[1;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     78\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n\u001B[1;32m---> 79\u001B[0m     count\u001B[38;5;241m.\u001B[39mscatter_add_(\u001B[38;5;241m0\u001B[39m, index, src\u001B[38;5;241m.\u001B[39mnew_ones(src\u001B[38;5;241m.\u001B[39msize(dim)))\n\u001B[0;32m     80\u001B[0m     count \u001B[38;5;241m=\u001B[39m count\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     82\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected index [4090] to be smaller than self [32] apart from dimension 0 and to be smaller size than src [128]"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "98992f60c0c48494"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
