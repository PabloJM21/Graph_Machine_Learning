{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb719674-c334-440d-af62-1aed8c57f1ec",
   "metadata": {},
   "source": [
    "# Dense GNN implementation\n",
    "\n",
    "In this exercise we are implementing a GNN from scratch using dense matrices.\n",
    "Note that as the memory requirement of a dense matrix scales quadratically with the number of nodes in a graph, this limits us to datasets with only small graphs. \n",
    "\n",
    "We will use the following dataset molHIV.\n",
    "\n",
    "For the network we need a message-passing layer and pooling function.\n",
    "\n",
    "1. Describe the datasets in your own words. Also talk about its features and statistical properties of the graphs and labels.\n",
    "1. Implement the class GCNLayer to perform one round of message passing. You may use any variant of message passing here.\n",
    "1. Implement a pooling layer like MeanPooling or SumPooling (or both).\n",
    "1. Implement a one-hot-encoding of the atom type (this will positively affect classification performance)\n",
    "1. Implement the model class GraphGCN that builds upon your GCNLayer and Pooling layer.\n",
    "1. Create and train a GraphGCN model on MolHIV. As MOlHIV is highly imbalanced, it will make sense to adapt class weights in your loss function.\n",
    "\n",
    "For the dataset molHIV we aim to reach something like 0.64 ROC (or higher). Note that for me the training was quite unstable, so several runs got stuck at 0.5.\n",
    "\n",
    "Note: In this exercise, we use PyG only for utilities and not to build models. Feel free to edit/ignore any of the provided code as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "id": "78608f62-c77d-4f16-a924-50843e5bcc85",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import numpy as np\n",
    "from ogb.graphproppred import PygGraphPropPredDataset,Evaluator\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "906e13d0-cf25-450f-948c-c8f3fa214850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.399507Z",
     "start_time": "2024-10-27T11:38:03.393972Z"
    }
   },
   "source": [
    "# find device\n",
    "if torch.cuda.is_available(): # NVIDIA\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # apple silicon\n",
    "    device = torch.device('mps') \n",
    "else:\n",
    "    device = torch.device('cpu') # fallback\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.403693Z",
     "start_time": "2024-10-27T11:38:03.401515Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "98f729826ee51a13",
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "76a3a3e8-b9cb-42d7-be0f-8c41a1304a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.425058Z",
     "start_time": "2024-10-27T11:38:03.419753Z"
    }
   },
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=F.relu):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, H: torch.Tensor, adj: torch.Tensor):\n",
    "        # Use batch matrix multiplication for batched adjacency and feature matrices\n",
    "        H_new = torch.bmm(adj, H)  # Batch matrix multiplication\n",
    "        H_new = torch.bmm(H_new, self.weight.unsqueeze(0).expand(H.size(0), -1, -1))  # Apply weight matrix\n",
    "        H_new = self.activation(H_new)\n",
    "        return H_new"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "f07521e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.452267Z",
     "start_time": "2024-10-27T11:38:03.446886Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, H: torch.Tensor, node_mask: torch.Tensor):\n",
    "        # H: [batch_size, max_num_nodes, hidden_features]\n",
    "        # node_mask: [batch_size, max_num_nodes], 1 for valid nodes, 0 for padded nodes\n",
    "\n",
    "        # Mask the node features\n",
    "        masked_H = H * node_mask.unsqueeze(-1)  # Broadcasting mask over features\n",
    "\n",
    "        # Sum over nodes\n",
    "        sum_H = masked_H.sum(dim=1)  # [batch_size, hidden_features]\n",
    "\n",
    "        # Count valid nodes per graph\n",
    "        num_nodes = node_mask.sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # Avoid division by zero\n",
    "        num_nodes = num_nodes.clamp(min=1)\n",
    "\n",
    "        # Compute mean\n",
    "        mean_H = sum_H / num_nodes  # [batch_size, hidden_features]\n",
    "\n",
    "        return mean_H\n"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "0bc412b3-5648-4f1f-88a0-f5a18a27a419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.458369Z",
     "start_time": "2024-10-27T11:38:03.454289Z"
    }
   },
   "source": [
    "class SumPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SumPooling, self).__init__()\n",
    "\n",
    "    def forward(self, H: torch.Tensor, node_mask: torch.Tensor):\n",
    "        # Mask the node features\n",
    "        masked_H = H * node_mask.unsqueeze(-1)\n",
    "        # Sum over nodes\n",
    "        sum_H = masked_H.sum(dim=1)\n",
    "        return sum_H\n"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "add7fe46-769b-4d5c-8c9a-115c877132e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.465298Z",
     "start_time": "2024-10-27T11:38:03.459377Z"
    }
   },
   "source": [
    "class GraphGCN(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, hidden_features: int, out_features: int, pooling='mean'):\n",
    "        super(GraphGCN, self).__init__()\n",
    "\n",
    "        # Define two GCN layers\n",
    "        self.gcn1 = GCNLayer(in_features, hidden_features)\n",
    "        self.gcn2 = GCNLayer(hidden_features, hidden_features)\n",
    "\n",
    "        # Define pooling layer\n",
    "        self.pooling = MeanPooling() if pooling == 'mean' else SumPooling()\n",
    "\n",
    "        # Define a linear layer for classification\n",
    "        self.classifier = torch.nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, H_in: torch.Tensor, adj: torch.Tensor, node_mask: torch.Tensor):\n",
    "        # Pass through the first GCN layer\n",
    "        H = self.gcn1(H_in, adj)\n",
    "\n",
    "        # Pass through the second GCN layer\n",
    "        H = self.gcn2(H, adj)\n",
    "\n",
    "        # Apply pooling to get a graph-level embedding, using the node_mask\n",
    "        H_pooled = self.pooling(H, node_mask)\n",
    "\n",
    "        # Classify using the pooled representation\n",
    "        out = self.classifier(H_pooled)\n",
    "\n",
    "        return out\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "id": "4c9a35b2",
   "metadata": {},
   "source": [
    "## MolHIV\n",
    "\n",
    "Pytorch Geometric stores its graphs in a sparse format using the variable edge_index.\n",
    "We will thus need to create our own (torch) dataloader and extract the graphs into dense adjacency matrices.\n",
    "\n",
    "In terms of model accuracy, it really helped me to add an \"Atom encoding\", i.e. a one-hot-encoding of the atoms instead of just having the atomic numbers appear in the first column of the node features."
   ]
  },
  {
   "cell_type": "code",
   "id": "4abc2004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.472389Z",
     "start_time": "2024-10-27T11:38:03.466307Z"
    }
   },
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, adjacencies, features, targets, num_nodes):\n",
    "        self.adjacencies = torch.tensor(adjacencies, dtype=torch.float32)\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "        self.num_nodes = torch.tensor(num_nodes, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adjacencies[idx], self.features[idx], self.targets[idx], self.num_nodes[idx]\n",
    "\n",
    "    def num_features(self):\n",
    "        return self.features.shape[-1]\n",
    "\n",
    "    def compute_class_weights(self):\n",
    "        unique_classes = torch.unique(self.targets).numpy()\n",
    "        weights = compute_class_weight('balanced', classes=unique_classes, y=self.targets.numpy())\n",
    "        return torch.tensor(weights, dtype=torch.float32)\n"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "7e1e0711-ea5a-4c92-979a-31053adbad79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:03.479712Z",
     "start_time": "2024-10-27T11:38:03.473396Z"
    }
   },
   "source": [
    "\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch.nn.functional as F\n",
    "def extract_graphs_and_features(dataset):\n",
    "    adjacencies = []\n",
    "    features = []\n",
    "    targets = []\n",
    "    num_nodes_list = []\n",
    "    atom_types = set()\n",
    "\n",
    "    max_nodes = max(data.num_nodes for data in dataset)\n",
    "\n",
    "    for data in dataset:\n",
    "        # Convert edge_index to a dense adjacency matrix and pad to max_nodes\n",
    "        adj = to_dense_adj(data.edge_index, max_num_nodes=max_nodes).squeeze(0)\n",
    "        adjacencies.append(adj)\n",
    "\n",
    "        # Pad feature matrix to max_nodes x num_features\n",
    "        num_nodes = data.num_nodes\n",
    "        num_nodes_list.append(num_nodes)\n",
    "        node_features = F.pad(data.x, (0, 0, 0, max_nodes - num_nodes))\n",
    "        features.append(node_features)\n",
    "\n",
    "        # Collect unique atom types\n",
    "        atom_types.update(data.x[:, 0].tolist())\n",
    "\n",
    "        # Append target label\n",
    "        targets.append(data.y)\n",
    "\n",
    "    # Create an atom type to index mapping\n",
    "    atoms_to_index = {atom: idx for idx, atom in enumerate(sorted(atom_types))}\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    adjacencies = torch.stack(adjacencies)\n",
    "    features = torch.stack(features)\n",
    "    targets = torch.tensor(targets, dtype=torch.long).squeeze()\n",
    "    num_nodes_tensor = torch.tensor(num_nodes_list, dtype=torch.long)\n",
    "\n",
    "    return adjacencies, features, targets, atoms_to_index, num_nodes_tensor\n"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "id": "8f15487e-5c77-44ad-83f9-aa9df8da20b4",
   "metadata": {},
   "source": [
    "### Create Data Loaders for MolHIV"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1fd2530-1131-4041-882e-4e73970a6f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:38.134615Z",
     "start_time": "2024-10-27T11:38:03.480724Z"
    }
   },
   "source": [
    "batch_size = 32\n",
    "\n",
    "molHIV = PygGraphPropPredDataset(name = \"ogbg-molhiv\") \n",
    "split_idx = molHIV.get_idx_split()\n",
    "all_adjacencies, all_features, all_targets, atoms_to_index, num_nodes = extract_graphs_and_features(molHIV)\n",
    "all_targets = all_targets.to(torch.int64)\n",
    "\n",
    "# Create datasets using split_idx indices\n",
    "graph_dataset = GraphDataset(all_adjacencies, all_features, all_targets, num_nodes)\n",
    "train_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"train\"])\n",
    "val_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"valid\"])\n",
    "test_dataset = torch.utils.data.Subset(graph_dataset, split_idx[\"test\"]) \n",
    "\n",
    "# Create DataLoaders\n",
    "# Adjust collate_fn to handle num_nodes if necessary\n",
    "def collate_fn(batch):\n",
    "    adjacencies, features, targets, num_nodes = zip(*batch)\n",
    "    adjacencies = torch.stack(adjacencies)\n",
    "    features = torch.stack(features)\n",
    "    targets = torch.stack(targets)\n",
    "    num_nodes = torch.stack(num_nodes)\n",
    "    return adjacencies, features, targets, num_nodes\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\Lib\\site-packages\\ogb\\graphproppred\\dataset_pyg.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_10820\\1768869534.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.adjacencies = torch.tensor(adjacencies, dtype=torch.float32)\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_10820\\1768869534.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.features = torch.tensor(features, dtype=torch.float32)\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_10820\\1768869534.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(targets, dtype=torch.long)\n",
      "C:\\Users\\dadoi\\AppData\\Local\\Temp\\ipykernel_10820\\1768869534.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.num_nodes = torch.tensor(num_nodes, dtype=torch.long)\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:38.167712Z",
     "start_time": "2024-10-27T11:38:38.155733Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "142db195311ebc02",
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "id": "db11527f",
   "metadata": {},
   "source": [
    "### Model and Training for MolHIV\n",
    "\n",
    "The evaluation of MolHIV (and all other datasets from ogb) should happen through an Evaluator. You can also try playing around with learning rate schedulers."
   ]
  },
  {
   "cell_type": "code",
   "id": "52980ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:38.272173Z",
     "start_time": "2024-10-27T11:38:38.171717Z"
    }
   },
   "source": [
    "evaluator = Evaluator(name='ogbg-molhiv')\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for adjacencies, features, targets, num_nodes in loader:\n",
    "        adjacencies, features, targets, num_nodes = adjacencies.to(device), features.to(device), targets.to(device), num_nodes.to(device)\n",
    "\n",
    "        # Create node mask\n",
    "        max_num_nodes = features.shape[1]\n",
    "        node_indices = torch.arange(max_num_nodes).unsqueeze(0).to(device)\n",
    "        node_mask = (node_indices < num_nodes.unsqueeze(1)).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(features, adjacencies, node_mask)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "        y_pred.append(preds.cpu())\n",
    "        y_true.append(targets.cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    input_dict = {\"y_true\": y_true.unsqueeze(1), \"y_pred\": y_pred.unsqueeze(1)}\n",
    "\n",
    "    return evaluator.eval(input_dict)['rocauc']\n"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "id": "00bd8864-bbbb-4a9e-a4ed-27233a9477f5",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T11:38:38.492857Z",
     "start_time": "2024-10-27T11:38:38.274239Z"
    }
   },
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for adjacencies, features, targets, num_nodes in train_loader:\n",
    "        adjacencies, features, targets, num_nodes = adjacencies.to(device), features.to(device), targets.to(device), num_nodes.to(device)\n",
    "\n",
    "        # Create node mask\n",
    "        max_num_nodes = features.shape[1]\n",
    "        node_indices = torch.arange(max_num_nodes).unsqueeze(0).to(device)  # Shape: [1, max_num_nodes]\n",
    "        node_mask = (node_indices < num_nodes.unsqueeze(1)).float()  # Shape: [batch_size, max_num_nodes]\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, adjacencies, node_mask)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Rest of your training loop...\n"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GraphGCN.forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[86], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 15\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(features, adjacencies, node_mask)\n\u001B[0;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Backward pass and optimization\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mTypeError\u001B[0m: GraphGCN.forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "705c57fe288296e4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
